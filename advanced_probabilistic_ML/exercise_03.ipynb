{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec2f2cbb158c2d8f03d616a694899ec7",
     "grade": false,
     "grade_id": "cell-81c5a400584e4a8f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## CS-E4820 Machine Learning: Advanced Probabilistic Methods (spring 2021)\n",
    "\n",
    "Pekka Marttinen, Santosh Hiremath, Tianyu Cui, Yogesh Kumar, Zheyang Shen, Alexander Aushev, Khaoula El Mekkaoui, Shaoxiong Ji, Alexander Nikitin, Sebastiaan De Peuter, Joakim JÃ¤rvinen.\n",
    "\n",
    "## Exercise 3, due on Tuesday February 9 at 23:00.\n",
    "\n",
    "### Contents\n",
    "1. Problem 1: Poisson-Gamma\n",
    "2. Problem 2: Multivariate Gaussian\n",
    "3. Problem 3: Posterior of regression weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38bb2e5ebde49e1760a076b099d6e5a6",
     "grade": false,
     "grade_id": "cell-573bbaa2ef327be0",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Problem 1: Poisson-Gamma\n",
    "\n",
    "Suppose you have $N$ i.i.d. observations $\\mathbf{x}= \\{x_i\\}_{i=1}^N$ from a $\\operatorname{Poisson}(\\lambda)$ distribution with a rate parameter $\\lambda$ that has a conjugate prior \n",
    "\n",
    "$$\\lambda \\sim \\operatorname{Gamma}(a,b)$$\n",
    "\n",
    "with the shape and rate hyperparameters $a$ and $b$. Derive the posterior distribution $\\lambda|\\bf{x}$.\n",
    "\n",
    "Write your solutions in LateX or attach a picture in the answer cell provided below. You can add a picture using the command ```!(imagename_in_the_folder.jpg)```. Latex in here works similarly as you would write it normally! You can use some of the definitions from the exercise description as a reference. The list of valid Latex commands in Jypyter notebook can be found here: http://www.onemathematicalcat.org/MathJaxDocumentation/TeXSyntax.htm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(\\lambda|x)=\\dfrac{p(x|\\lambda)p(\\lambda)}{p(x)}$\\\\\n",
    "\n",
    "In conjugate prior posterior is available in closed form\n",
    "\n",
    "$p(\\lambda|x)=p(x|\\lambda)p(\\lambda)$\n",
    "\n",
    "$N*Poisson(x; \\lambda) = \\prod_{i=1}^N\\dfrac{\\lambda^xe^{-\\lambda}}{x!}=\\dfrac{\\lambda^{\\sum_{i=1}^Nx_i}e^{-n\\lambda}}{\\prod_{i=1}^Nx_i!}$\n",
    "\n",
    "$Gamma(\\lambda; a,b)=\\dfrac{b^a\\lambda^{a-1}e^{-b\\lambda}}{\\Gamma (a)} = \\dfrac{b^a\\lambda^{a-1}e^{-b\\lambda}}{(a-1)!}$, when $a$ is a positive integer\n",
    "\n",
    "$p(x|\\lambda)p(\\lambda)=\\dfrac{\\lambda^{\\sum_{i=1}^Nx_i}e^{-n\\lambda}}{\\prod_{i=1}^Nx_i!}\\dfrac{b^a\\lambda^{a-1}e^{-b\\lambda}}{(a-1)!} \\propto e^{-\\lambda(n+b)}\\lambda^{\\sum_{i=1}^Nx_i+a-1}$\n",
    "\n",
    "$p(\\lambda|x) \\propto e^{-\\lambda(n+b)}\\lambda^{\\sum_{i=1}^Nx_i+a-1} $\n",
    "\n",
    "We can see, that posterior is gamma distributed $Gamma(x; \\alpha,\\beta)$, where $\\alpha=\\sum_{i=1}^Nx_i+a$ and $\\beta=n+b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c2d1bd8470ba33c5aa2596654e3cefbc",
     "grade": false,
     "grade_id": "cell-7fdfccb96ae5c3d1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Problem 2: Multivariate Gaussian\n",
    "\n",
    "Suppose we have $N$ i.i.d. observations $\\mathbf{X} = \\{\\mathbf{x}_i\\}_{i=1}^N$ from a multivariate Gaussian distribution $$\\mathbf{x}_i \\mid \\boldsymbol{\\mu} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$$ with unknown mean parameter $\\boldsymbol{\\mu}$  and a known covariance matrix $\\boldsymbol{\\Sigma}$. As prior information on the mean parameter we have $$ \\boldsymbol{\\mu} \\sim \\mathcal{N}(\\mathbf{m_0}, \\mathbf{S_0}). $$\n",
    "\n",
    "__(a)__ Derive the posterior distribution $p(\\boldsymbol{\\mu}|\\mathbf{X})$ of the mean parameter $\\boldsymbol{\\mu}$. Write your solution in LateX or attach a picture of the solution in the cell below.\n",
    "\n",
    "__(b)__ Compare the Bayesian estimate (posterior mean) to the maximum likelihood estimate by generating $N=10$ observations from the bivariate Gaussian \n",
    "        $$\\mathcal{N}\\left(\\begin{bmatrix}0 \\\\ 0\\end{bmatrix}, \\begin{bmatrix}1 & 0 \\\\ 0 & 1\\end{bmatrix}\\right).$$\n",
    "For this you can use the Python function [numpy.random.normal](https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.normal.html), making use of the fact that the elements of the bivariate random vectors are independent. In the Bayesian case, use the prior with $\\mathbf{m_0} = [0,0]^T$ and $\\mathbf{S_0} = [\\begin{smallmatrix}0.1 & 0 \\\\ 0 & 0.1\\end{smallmatrix}]$. Report both estimates. Is the Bayesian estimate closer to the true value $\\boldsymbol{\\mu} = [0,0]^T$? Use the code template given below (after the answer cell) to complete your answer.\n",
    "\n",
    "Write your solutions to __(a)__ and __(b)__ in LateX or attach a picture in the answer cell provided below. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)\n",
    "$p(\\mu|X)=\\dfrac{p(x|\\mu)p(\\mu)}{p(x)} \\propto p(\\mu)p(x|\\mu)$ \n",
    "\n",
    "$p(\\mu)=\\dfrac{e^{-\\dfrac{1}{2}(\\mu-m_0)^TS_0^{-1}(\\mu-m_0)}}{\\sqrt{2\\pi|S_0|}}$ \n",
    "\n",
    "$p(x|\\mu)=\\prod_{i=1}^N\\dfrac{e^{-\\dfrac{1}{2}(x_i-\\mu)^T\\Sigma^{-1}(x_i-\\mu)}}{\\sqrt{2\\pi|\\Sigma|}}$ \n",
    "\n",
    "$p(\\mu|X)=\\dfrac{e^{-\\dfrac{1}{2}(\\mu-m_0)^TS_0^{-1}(\\mu-m_0)}}{\\sqrt{2\\pi|S_0|}} \\prod_{i=1}^N\\dfrac{e^{-\\dfrac{1}{2}(x_i-\\mu)^T\\Sigma^{-1}(x_i-\\mu)}}{\\sqrt{2\\pi|\\Sigma|}}$ \n",
    "\n",
    "$p(\\mu|X) \\propto e^{-\\dfrac{1}{2}(\\mu-m_0)^TS_0^{-1}(\\mu-m_0)} e^{-\\dfrac{1}{2}\\sum_{i=1}^N(x_i-\\mu)^T\\Sigma^{-1}(x_i-\\mu)}$ \n",
    "\n",
    "$=e^{-\\dfrac{1}{2}(\\mu-m_0)^TS_0^{-1}(\\mu-m_0)-\\dfrac{1}{2}\\sum_{i=1}^N(x_i-\\mu)^T\\Sigma^{-1}(x_i-\\mu)}$\n",
    "\n",
    "$ln(p(\\mu|X))=-\\dfrac{1}{2}(\\mu-m_0)^TS_0^{-1}(\\mu-m_0)-\\dfrac{1}{2}\\sum_{i=1}^N(x_i-\\mu)^T\\Sigma^{-1}(x_i-\\mu)$\n",
    "\n",
    "$=-\\dfrac{1}{2}\\mu^TS_0^{-1}\\mu+\\mu^TS_0^{-1}m_0-\\dfrac{1}{2}N\\mu^T\\Sigma^{-1}\\mu+\\sum_{i=1}^N\\mu^T\\Sigma^{-1}x_i$\n",
    "\n",
    "$=-\\dfrac{1}{2}\\mu^T(S_0^{-1}+N\\Sigma^{-1})\\mu+\\mu^T(S_0^{-1}m_0+\\Sigma^{-1}\\sum_{i=1}^Nx_i)$ \n",
    "\n",
    "This can be reordered \n",
    "\n",
    "$-\\dfrac{1}{2}(\\mu-(S_0^{-1}+N\\Sigma^{-1})^{-1}(S_0^{-1}m_0+\\Sigma^{-1}\\sum_{i=1}^Nx_i))^T(S_0^{-1}+N\\Sigma^{-1})(\\mu-(S_0^{-1}+N\\Sigma^{-1})^{-1}(S_0^{-1}m_0+\\Sigma^{-1}\\sum_{i=1}^Nx_i))$ \n",
    "\n",
    "This is gaussian $\\mathcal{N}(\\mu_n, \\Sigma_n)$, when\n",
    "\n",
    "$\\mu_n=(S_0^{-1}+N\\Sigma^{-1})^{-1}(S_0^{-1}m_0+\\Sigma^{-1}\\sum_{i=1}^Nx_i)$\n",
    "\n",
    "$\\Sigma_n=(S_0^{-1}+N\\Sigma^{-1})^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af88913931d4649db8324917756a5b72",
     "grade": false,
     "grade_id": "cell-e6a09ef8bf1f72d3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: \n",
      " [[ 0.33526765 -0.00860153]\n",
      " [ 0.29285634  0.90868158]\n",
      " [-0.10942395  1.25869074]\n",
      " [-0.90134176  1.06659515]\n",
      " [ 0.65464056  0.4332347 ]\n",
      " [ 1.53357849  1.27963328]\n",
      " [-0.64100562  0.69549516]\n",
      " [ 0.14274765 -1.87475444]\n",
      " [-0.37083495  0.82997198]\n",
      " [-0.24765381  1.81898079]] \n",
      "\n",
      "MLE:  [0.06888306 0.64079274] \n",
      "\n",
      "Posterior mean:  [0.03444153 0.32039637]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# template for 2(b)\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "\n",
    "Sz = np.array([[0.1, 0],[0, 0.1]])\n",
    "Sigma = np.array([[1, 0],[0, 1]])\n",
    "mu=np.array([0, 0])\n",
    "N = 10\n",
    "m0=np.array([[0],[0]])\n",
    "x = np.random.multivariate_normal(mean=mu, cov=Sigma, size=N)\n",
    "\n",
    "\n",
    "# Sample N bivariate normal vectors\n",
    "# compute MLE and also the posterior mean solution\n",
    "\n",
    "mle = x.mean(axis=0) #EXERCISE\n",
    "posterior_mean = inv((inv(Sz)+N*inv(Sigma)))@(inv(Sigma)@np.transpose(np.sum(x, axis=0))) #EXERCISE \n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"Samples: \\n\",x,'\\n')\n",
    "\n",
    "print(\"MLE: \",mle,'\\n')\n",
    "\n",
    "print(\"Posterior mean: \",posterior_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that the Bayesian estimate is closer to real mean \\[0, 0\\]$^T$. This could be, because MLE tends to overfit, while prior affects to posterior mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ddf1e85bf2fabec6a07c3676a5945499",
     "grade": false,
     "grade_id": "cell-6f265c79745ea700",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "# Problem 3: Posterior of regression weights\n",
    "\n",
    "Suppose $y_{i}=\\mathbf{w}^{T}\\mathbf{x}_{i}+\\epsilon_{i},$ for $i=1,\\ldots,n,$ where $\\epsilon_{i}\\sim \\mathcal{N}(0,\\beta^{-1})$. Assume a prior $$\\mathbf{w} \\sim \\mathcal{N} (\\mathbf{0},\\alpha^{-1}\\mathbf{I}).$$ Use 'completing the square' to show that the posterior of $\\mathbf{w}$ is given by $p(\\mathbf{w} \\mid \\mathbf{y}, \\mathbf{x}, \\alpha, \\beta)=\\mathcal{N}(\\mathbf{w} \\mid \\mathbf{m}, \\mathbf{S}),$ where \n",
    "\\begin{align*}\n",
    "    \\mathbf{S} &= \\left( \\alpha \\mathbf{I} + \\beta \\sum_{i=1}^n \\mathbf{x}_i \\mathbf{x}_i^T \\right)^{-1}\\;, \\\\\n",
    "    \\mathbf{m} &= \\beta \\mathbf{S} \\sum_{i=1}^{n} y_i \\mathbf{x}_i.\n",
    "\\end{align*}\n",
    "\n",
    "Write your solution in LateX or attach a picture of the solution in the cell below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Starting point\n",
    "\n",
    "\n",
    "$Y=w^TX+\\epsilon$\n",
    "\n",
    "$y=N(w^Tx,\\beta^{-1})$\n",
    "\n",
    "$D=(y, x, \\alpha, \\beta)$ \n",
    "\n",
    "Posterior:\n",
    "\\begin{align*}\n",
    "    p(w|D) \\propto p(D|w)p(w)\n",
    "\\end{align*}\n",
    "\n",
    "## Counting p(D|w)\n",
    "\n",
    "\n",
    "$p(D|w)=p(Y|X,w)=\\prod_{i=1}^np(y_i|x_i,w) $\n",
    "\n",
    "$=\\prod_{i=1}^n\\dfrac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\dfrac{1}{2\\sigma^2}(y_i-w^Tx_i)^2} $\n",
    "\n",
    "$=(\\dfrac{1}{\\sqrt{2\\pi\\sigma^2}})^ne^{-\\dfrac{1}{2\\sigma^2}\\sum_{i=1}^n(y_i-w^Tx_i)^2} $\n",
    "\n",
    "$\\sum_{i=1}^na_i^2=a^Ta$\n",
    "\n",
    "$y_i-w^Tx_i=[y_1-w^Tx_1, ... , y_n-w^Tx_n]^T=[y_1,...,y_n]^T-[x^T_1w,...,x^T_nw]^T=Y-[x^T_1,...,x^T_n]^Tw=Y-Aw$, $A$ is a design matrix. \n",
    "\n",
    "$\\sum_{i=1}^n(y_i-w^Tx_i)^2=(Y-Aw)^T(Y-Aw)$\n",
    "\n",
    "$p(D|w)=(\\dfrac{1}{\\sqrt{2\\pi\\sigma^2}})^ne^{-\\dfrac{1}{2\\sigma^2}(Y-Aw)^T(Y-Aw)}\\propto e^{-\\dfrac{1}{2\\sigma^2}(Y-Aw)^T(Y-Aw)}$\n",
    "\n",
    "$\\sigma^2=\\beta^{-1}$, so we get that \n",
    "\n",
    "\\begin{align*}\n",
    "    p(D|w) \\propto e^{-\\dfrac{\\beta}{2}(Y-Aw)^T(Y-Aw)}\n",
    "\\end{align*}\n",
    "\n",
    "## Counting p(w)\n",
    "\n",
    "\\begin{align*}\n",
    "p(w)=e^{-\\dfrac{\\alpha}{2}\\sum_{i=1}^n(w_i-0)^2}=e^{-\\dfrac{\\alpha}{2}\\sum_{i=1}^n(w_i)^2}=e^{-\\dfrac{\\alpha}{2}w^Tw}\n",
    "\\end{align*}\n",
    "\n",
    "## Join equations\n",
    "\n",
    "$p(w|D) \\propto p(D|w)p(w) \\propto e^{-\\dfrac{\\beta}{2}(Y-Aw)^T(Y-Aw)} e^{-\\dfrac{\\alpha}{2}w^Tw} $\n",
    "\n",
    "$= e^{-\\dfrac{\\beta}{2}(Y-Aw)^T(Y-Aw)-\\dfrac{\\alpha}{2}w^Tw}$ \n",
    "\n",
    "We can get rid of $e$ and $\\dfrac{1}{2}$\n",
    "\n",
    "$-\\beta (Y-Aw)^T(Y-Aw)-\\alpha w^Tw = \\beta (Y^TY-2w^TAY+w^TA^TAw)+\\alpha w^Tw$\n",
    "\n",
    "$= \\beta Y^TY-2\\beta w^TAY+w^T(\\beta A^TA+\\alpha I )w$\n",
    "\n",
    "##  Completing the square\n",
    "\n",
    "$(w-\\mu)^T\\Lambda (w-\\mu) = w^T\\Lambda w -2w^T\\Lambda\\mu + const $ (wrt w)\n",
    "\n",
    "Thus, from the last equation from \"Join equations\" section, $\\Lambda=\\beta A^TA+\\alpha I$\n",
    "\n",
    "Additionally, we can calculate $-2\\beta w^TAY=-2w^T\\Lambda\\mu \\rightarrow \\mu=\\beta \\Lambda^{-1} AY$\n",
    "\n",
    "Everything else is constant with respect to w, so we get that $p(w|D) =N(w|\\mu,\\Lambda^{-1}) $\n",
    "\n",
    "In our equation, $AY=\\sum_{i=1}^ny_ix_i$, $A^TA=\\sum_{i=1}^nx_ix_i^T$, $S=\\Lambda^{-1}$.  \n",
    "\n",
    "$m=\\beta S \\sum_{i=1}^ny_ix_i$.\n",
    "\n",
    "\n",
    "## Answer\n",
    "\n",
    "\\begin{align*}\n",
    "p(w|D)=N(w|m, S),\n",
    "\\end{align*}\n",
    "\n",
    "where $m=\\beta S \\sum_{i=1}^ny_ix_i$,\n",
    "\n",
    "$S=(\\beta \\sum_{i=1}^nx_ix_i^T+\\alpha I)^{-1}$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
